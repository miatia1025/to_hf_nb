{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOBTBhrXjchu"
      },
      "source": [
        "# 爆破用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xei0B3YdN0zV"
      },
      "outputs": [],
      "source": [
        "# @markdown #💣削除用！注意！  \n",
        "# @markdown 例 : `/content/test`で`/content/test`を中身ごと削除  \n",
        "import shutil\n",
        "dir = \"/content/test\" # @param{type:\"string\"}\n",
        "shutil.rmtree(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH8ICufuRbJN"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZtl8zeNj70a"
      },
      "source": [
        "# Create repo, Download, Upload to 🤗"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7WqHtbR0Tng",
        "outputId": "aca7ddd8-54f7-483f-f1f3-b8ed66a15dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/日本 語 スペ ース もあ るよ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nUcQXKCI5Vo4",
        "outputId": "6dc5d51e-6533-46df-8510-e1466ef40aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (1.24.3)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n",
            "[Errno 2] No such file or directory: 'where_to_download_local'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# git lfs initializer\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##installing requirements\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #🌱Initializer Area\n",
        "!pip install huggingface_hub\n",
        "!pip install --upgrade gdown\n",
        "\n",
        "import os\n",
        "where_to_download_local = \"/content/test\" #@param {type:\"string\"}\n",
        "if not os.path.exists(where_to_download_local):\n",
        "    os.makedirs(where_to_download_local)\n",
        "%cd {where_to_download_local}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2yLswpvSV-n"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##create a repo as model, dataset or space\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #🤗 Creating Repo Area\n",
        "repo_name = \"user_name/repo_id\" # @param{type:\"string\"}\n",
        "token = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXX\" # @param{type:\"string\"}\n",
        "\n",
        "if token:\n",
        "  hf_token = token\n",
        "\n",
        "repo_type = \"model\" # @param[\"model\", \"dataset\", \"space\"] {allow-input:true}\n",
        "if repo_type not in [\"model\", \"dataset\", \"space\"]:\n",
        "  repo_type = None\n",
        "\n",
        "private = True # @param{type:\"boolean\"}\n",
        "\n",
        "from huggingface_hub import create_repo, login, HfApi\n",
        "login(token=token)\n",
        "create_repo(repo_id=repo_name, repo_type=repo_type, private=private, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vKR_BDrsh1d"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##Download entire 🤗 repo ( from model, space and dataset )\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #🤗 Download Repo Area\n",
        "\n",
        "from huggingface_hub import snapshot_download, login\n",
        "\n",
        "# enter repo id\n",
        "repo_name = \"user_name/repo_id\" # @param {type:\"string\"}\n",
        "\n",
        "# login\n",
        "token = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # @param {type:\"string\"}\n",
        "if token:\n",
        "  hf_token = token\n",
        "login(token=hf_token)\n",
        "\n",
        "# select repo type\n",
        "repo_type = \"dataset\" # @param[\"model\", \"dataset\", \"space\"] {allow-input:true}\n",
        "if repo_type not in [\"model\", \"dataset\", \"space\"]:\n",
        "  repo_type = None\n",
        "\n",
        "# filters using fnmatch\n",
        "allow_fnmatch_list = \"\" # @param {type:\"string\"}\n",
        "ignore_fnmatch_list = \"\" # @param {type:\"string\"}\n",
        "\n",
        "patterns_list = [allow_fnmatch_list, ignore_fnmatch_list]\n",
        "\n",
        "patterns_list = [\n",
        "    [pattern.strip() for pattern in patterns.split(\",\")]\n",
        "    for patterns in patterns_list\n",
        "]\n",
        "\n",
        "# execute\n",
        "if allow_fnmatch_list:\n",
        "  snapshot_download(\n",
        "      repo_id=repo_name,\n",
        "      repo_type=repo_type,\n",
        "      allow_patterns=patterns_list[0],\n",
        "      ignore_patterns=patterns_list[1],\n",
        "      )\n",
        "else:\n",
        "  snapshot_download(\n",
        "      repo_id=repo_name,\n",
        "      repo_type=repo_type,\n",
        "      ignore_patterns=patterns_list[1],\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58RG10LI486S"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##downloading area (civitai, 🤗, gigafile)\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #⬇️Downloading Area\n",
        "\n",
        "## for regex\n",
        "import re\n",
        "\n",
        "## Variables\n",
        "MODEL_URLS = \"https://drive.google.com/file/d/1LvMMwELs8bE3TMiyN6mFxazVe_Fk0Tus/view?usp=drivesdk\" # @param {type:\"string\"}\n",
        "urls_list = [url.strip() for url in MODEL_URLS.split(',')]\n",
        "\n",
        "SAVE_AS_CHECK = False # @param {type:\"boolean\"}\n",
        "SAVE_AS_FILENAMES = \"a.file, b.file, c.file\" # @param {type:\"string\"}\n",
        "filenames_list = [url.strip() for url in SAVE_AS_FILENAMES.split(',')]\n",
        "\n",
        "## Download with Gigafile Check\n",
        "try:\n",
        "  if SAVE_AS_CHECK:\n",
        "    assert len(urls_list)==len(filenames_list)\n",
        "except AssertionError:\n",
        "  print(\"Error: MODEL_URLS and SAVE_AS_FILENAMES have different lengths.\")\n",
        "else:\n",
        "  for i in range(len(urls_list)):\n",
        "    MODEL_URL = urls_list[i]\n",
        "    GIGA_CHECK = \"gigafile.nu\" in MODEL_URL\n",
        "    GOOGLE_CHECK = \"drive.google.com\" in MODEL_URL\n",
        "\n",
        "    if GIGA_CHECK:\n",
        "      BUTTON_URL = MODEL_URL.replace(\"gigafile.nu/\", \"gigafile.nu/download.php?file=\")\n",
        "      GET_GARBAGE = re.search(r\"[^/]*$\", MODEL_URL).group()\n",
        "      print(GET_GARBAGE)\n",
        "      !wget --keep-session-cookies --save-cookies=cookies.txt $MODEL_URL\n",
        "\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget --load-cookies cookies.txt -O $SAVE_AS_FILENAME $BUTTON_URL\n",
        "      else: \n",
        "        !wget --load-cookies cookies.txt $BUTTON_URL --content-disposition\n",
        "\n",
        "      # clean for gigafile\n",
        "      !rm ./cookies.txt\n",
        "      !rm ./{GET_GARBAGE}\n",
        "\n",
        "    elif GOOGLE_CHECK:\n",
        "      if \"/file/d/\" in MODEL_URL:\n",
        "        drive_id = re.search(r\"(?<=/file/d/)[\\w-]+\", MODEL_URL).group(0)\n",
        "      else:\n",
        "        drive_id = re.search(r\"(?<=id=)[\\w-]+\", MODEL_URL).group(0)\n",
        "        \n",
        "      !gdown {drive_id}\n",
        "\n",
        "    else:\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget -O $SAVE_AS_FILENAME $MODEL_URL\n",
        "      else:\n",
        "        !wget $MODEL_URL --content-disposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccbDfX1zqC7Q"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##Uploading your files to the repo\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #🤗 Uploading Area\n",
        "import os\n",
        "\n",
        "repo_to_upload = \"\" #@param {type:\"string\"}\n",
        "if repo_to_upload:\n",
        "  repo_name = repo_to_upload\n",
        "\n",
        "source_path = \"/content/test\" #@param {type:\"string\"}\n",
        "destination_folder = \"\" #@param {type:\"string\"}\n",
        "\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "if token:\n",
        "  hf_token = token\n",
        "\n",
        "repo_type = \"\" # @param[\"model\", \"dataset\", \"space\"] {allow-input:true}\n",
        "if repo_type:\n",
        "  if repo_type not in [\"model\", \"dataset\", \"space\"]:\n",
        "    repo_type = None\n",
        "\n",
        "  hf_repo_type = repo_type\n",
        "\n",
        "ignore_fnmatch = \".txt, .json\" #@param {type:\"string\"}\n",
        "fnmatch_list = [url.strip() for url in ignore_fnmatch.split(',')]\n",
        "\n",
        "if os.path.exists(source_path) and os.path.isfile(source_path):\n",
        "  filename = os.path.basename(source_path)\n",
        "  if destination_folder:\n",
        "    if re.search(\"/$\", destination_folder):\n",
        "      destination_folder = destination_folder + filename\n",
        "    else:\n",
        "      destination_folder = destination_folder + \"/\" + filename\n",
        "\n",
        "  HfApi().upload_file(\n",
        "      path_or_fileobj=source_path,\n",
        "      path_in_repo=destination_folder,\n",
        "      repo_id=repo_name,\n",
        "      repo_type=hf_repo_type,\n",
        "  )\n",
        "\n",
        "elif os.path.exists(source_path) and os.path.isdir(source_path):\n",
        "  HfApi().upload_folder(\n",
        "      folder_path=source_path,\n",
        "      path_in_repo=destination_folder,\n",
        "      repo_id=repo_name,\n",
        "      ignore_patterns=fnmatch_list,\n",
        "      repo_type=hf_repo_type,\n",
        "  )\n",
        "\n",
        "else:\n",
        "  print(\"{source_path} is not found\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lOBTBhrXjchu",
        "cZtl8zeNj70a"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "67cbb8304b1b100a1c94f05aa8aefc1e7bd2e504a89629ea25a23c5690fcef87"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}