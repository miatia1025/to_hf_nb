{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOBTBhrXjchu"
      },
      "source": [
        "# ÁàÜÁ†¥Áî®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xei0B3YdN0zV"
      },
      "outputs": [],
      "source": [
        "# @markdown #üí£ÂâäÈô§Áî®ÔºÅÊ≥®ÊÑèÔºÅ  \n",
        "# @markdown ‰æã : `/content/test`„Åß`/content/test`„Çí‰∏≠Ë∫´„Åî„Å®ÂâäÈô§  \n",
        "import shutil\n",
        "dir = \"/content/test\" # @param{type:\"string\"}\n",
        "shutil.rmtree(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH8ICufuRbJN"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpZpgcHzjgvH"
      },
      "source": [
        "# git clone -> „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ -> push „Åæ„Åß"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaYbVn4QQcBv"
      },
      "outputs": [],
      "source": [
        "# git lfs initializer\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##installing requirements\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #üå±Initializer Area\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "!pip install huggingface_hub\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFY3aEWD_D81"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##setting variables and cloning repository\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #ü§ó Init Area\n",
        "\n",
        "## Token\n",
        "hf_token = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # @param{type:\"string\"}\n",
        "\n",
        "## Cloning Repo \n",
        "hf_repo_to_push = \"https://huggingface.co/user_id/repo_id\" # @param{type:\"string\"}\n",
        "hf_index = hf_repo_to_push.find(\"huggingface.co\")\n",
        "hf_repo_to_push = hf_repo_to_push[:hf_index] + \":\" + hf_token + \"@\" + hf_repo_to_push[hf_index:]\n",
        "\n",
        "!git clone $hf_repo_to_push\n",
        "\n",
        "## Set LFS and Dive into Repo\n",
        "hf_dir = hf_repo_to_push[hf_repo_to_push.rfind('/') + 1:]\n",
        "\n",
        "!huggingface-cli lfs-enable-largefiles $hf_dir\n",
        "%cd $hf_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaoEEGSmA22k"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##downloading area (civitai, ü§ó, gigafile)\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #‚¨áÔ∏èDownloading Area\n",
        "\n",
        "## for regex\n",
        "import re\n",
        "\n",
        "## Variables\n",
        "MODEL_URLS = \"https://civitai.com/api/download/models/11657, https://huggingface.co/unkounko/BalloonMix/resolve/main/LoRA/balloon.pt, https://tenor.com/view/%E3%81%A1%E3%81%83%E3%81%8B%E3%82%8F-gif-26614648\" # @param {type:\"string\"}\n",
        "urls_list = [url.strip() for url in MODEL_URLS.split(',')]\n",
        "\n",
        "SAVE_AS_CHECK = False # @param {type:\"boolean\"}\n",
        "SAVE_AS_FILENAMES = \"fileB.file, fileC.file, fileD.file\" # @param {type:\"string\"}\n",
        "filenames_list = [url.strip() for url in SAVE_AS_FILENAMES.split(',')]\n",
        "\n",
        "## Download with Gigafile Check\n",
        "try:\n",
        "  if SAVE_AS_CHECK:\n",
        "    assert len(urls_list)==len(filenames_list)\n",
        "except AssertionError:\n",
        "  print(\"Error: MODEL_URLS and SAVE_AS_FILENAMES have different lengths.\")\n",
        "else:\n",
        "  for i in range(len(urls_list)):\n",
        "    MODEL_URL = urls_list[i]\n",
        "    GIGA_CHECK = \"gigafile.nu\" in MODEL_URL\n",
        "\n",
        "    if GIGA_CHECK:\n",
        "      BUTTON_URL = MODEL_URL.replace(\"gigafile.nu/\", \"gigafile.nu/download.php?file=\")\n",
        "      GET_GARBAGE = re.search(r\"[^/]*$\", MODEL_URL).group()\n",
        "      print(GET_GARBAGE)\n",
        "      !wget --keep-session-cookies --save-cookies=cookies.txt $MODEL_URL\n",
        "\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget --load-cookies cookies.txt -O $SAVE_AS_FILENAME $BUTTON_URL\n",
        "      else: \n",
        "        !wget --load-cookies cookies.txt $BUTTON_URL --content-disposition\n",
        "\n",
        "      # clean for gigafile\n",
        "      !rm ./cookies.txt\n",
        "      !rm ./{GET_GARBAGE}\n",
        "    else:\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget -O $SAVE_AS_FILENAME $MODEL_URL\n",
        "      else:\n",
        "        !wget $MODEL_URL --content-disposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsLnd_fJXRL4"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##git add, git commit, git push\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #üåøGitting Area\n",
        "\n",
        "## staging\n",
        "!git add .\n",
        "\n",
        "!git status\n",
        "!git lfs status\n",
        "\n",
        "## commit and push\n",
        "COMMIT_MESSAGE = \"kjgffh afiu yagb\" # @param {type:\"string\"}\n",
        "USER_NAME = \"tinge\" # @param {type:\"string\"}\n",
        "USER_EMAIL = \"tinge\" # @param {type:\"string\"}\n",
        "\n",
        "!git config --global user.email $USER_EMAIL\n",
        "!git config --global user.name $USER_NAME\n",
        "!git commit -m \"$COMMIT_MESSAGE\"\n",
        "!git push\n",
        "\n",
        "#%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZtl8zeNj70a"
      },
      "source": [
        "# ‰ª•‰∏ãÂ∑•‰∫ã‰∏≠"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# git lfs initializer\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##installing requirements\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #üå±Initializer Area\n",
        "!pip install huggingface_hub\n",
        "!pip install --upgrade gdown"
      ],
      "metadata": {
        "id": "nUcQXKCI5Vo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2yLswpvSV-n"
      },
      "outputs": [],
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##create a repo as model, dataset or space\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #ü§ó Creating Repo Area\n",
        "repo_name = \"user_id/repo_id\" # @param{type:\"string\"}\n",
        "token = \"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" # @param{type:\"string\"}\n",
        "\n",
        "if token:\n",
        "  hf_token = token\n",
        "\n",
        "repo_type = \"model\" # @param[\"model\", \"dataset\", \"space\"] {allow-input:true}\n",
        "if repo_type not in [\"model\", \"dataset\", \"space\"]:\n",
        "  repo_type = None\n",
        "\n",
        "  private = True # @param{type:\"boolean\"}\n",
        "\n",
        "from huggingface_hub import create_repo, login, HfApi\n",
        "login(token=token)\n",
        "create_repo(repo_id=repo_name, repo_type=repo_type, private=private, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##downloading area (civitai, ü§ó, gigafile)\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #‚¨áÔ∏èDownloading Area\n",
        "\n",
        "## for regex\n",
        "import re\n",
        "\n",
        "## Variables\n",
        "MODEL_URLS = \"https://civitai.com/api/download/models/11657, https://huggingface.co/unkounko/BalloonMix/resolve/main/LoRA/balloon.pt, https://tenor.com/view/%E3%81%A1%E3%81%83%E3%81%8B%E3%82%8F-gif-26614648\" # @param {type:\"string\"}\n",
        "urls_list = [url.strip() for url in MODEL_URLS.split(',')]\n",
        "\n",
        "SAVE_AS_CHECK = False # @param {type:\"boolean\"}\n",
        "SAVE_AS_FILENAMES = \"a.file, b.file, c.file\" # @param {type:\"string\"}\n",
        "filenames_list = [url.strip() for url in SAVE_AS_FILENAMES.split(',')]\n",
        "\n",
        "## Download with Gigafile Check\n",
        "try:\n",
        "  if SAVE_AS_CHECK:\n",
        "    assert len(urls_list)==len(filenames_list)\n",
        "except AssertionError:\n",
        "  print(\"Error: MODEL_URLS and SAVE_AS_FILENAMES have different lengths.\")\n",
        "else:\n",
        "  for i in range(len(urls_list)):\n",
        "    MODEL_URL = urls_list[i]\n",
        "    GIGA_CHECK = \"gigafile.nu\" in MODEL_URL\n",
        "    GOOGLE_CHECK = \"drive.google.com\" in MODEL_URL\n",
        "\n",
        "    if GIGA_CHECK:\n",
        "      BUTTON_URL = MODEL_URL.replace(\"gigafile.nu/\", \"gigafile.nu/download.php?file=\")\n",
        "      GET_GARBAGE = re.search(r\"[^/]*$\", MODEL_URL).group()\n",
        "      print(GET_GARBAGE)\n",
        "      !wget --keep-session-cookies --save-cookies=cookies.txt $MODEL_URL\n",
        "\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget --load-cookies cookies.txt -O $SAVE_AS_FILENAME $BUTTON_URL\n",
        "      else: \n",
        "        !wget --load-cookies cookies.txt $BUTTON_URL --content-disposition\n",
        "\n",
        "      # clean for gigafile\n",
        "      !rm ./cookies.txt\n",
        "      !rm ./{GET_GARBAGE}\n",
        "\n",
        "    elif GOOGLE_CHECK:\n",
        "      if \"/file/d/\" in MODEL_URL:\n",
        "        drive_id = re.search(r\"(?<=/file/d/)[\\w-]+\", MODEL_URL).group(0)\n",
        "      else:\n",
        "        drive_id = re.search(r\"(?<=id=)[\\w-]+\", MODEL_URL).group(0)\n",
        "        \n",
        "      !gdown {drive_id}\n",
        "\n",
        "    else:\n",
        "      if SAVE_AS_CHECK:\n",
        "        SAVE_AS_FILENAME = filenames_list[i]\n",
        "        !wget -O $SAVE_AS_FILENAME $MODEL_URL\n",
        "      else:\n",
        "        !wget $MODEL_URL --content-disposition"
      ],
      "metadata": {
        "id": "58RG10LI486S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <hr>\n",
        "\n",
        "# @markdown ##Uploading your files to the repo\n",
        "# @markdown <hr>\n",
        "\n",
        "# @markdown #ü§ó Uploading Area\n",
        "import os\n",
        "\n",
        "source_path = \"/content/testfolder\" #@param {type:\"string\"}\n",
        "destination_folder = \"aabb_01/a\" #@param {type:\"string\"}\n",
        "ignore_fnmatch = \".txt, .json\" #@param {type:\"string\"}\n",
        "fnmatch_list = [url.strip() for url in ignore_fnmatch.split(',')]\n",
        "\n",
        "if os.path.exists(source_path) and os.path.isfile(source_path):\n",
        "  filename = os.path.basename(source_path)\n",
        "  if destination_folder:\n",
        "    if re.search(\"/$\", destination_folder):\n",
        "      destination_folder = destination_folder + filename\n",
        "    else:\n",
        "      destination_folder = destination_folder + \"/\" + filename\n",
        "\n",
        "  HfApi().upload_file(\n",
        "      path_or_fileobj=source_path,\n",
        "      path_in_repo=destination_folder,\n",
        "      repo_id=repo_name,\n",
        "  )\n",
        "\n",
        "elif os.path.exists(source_path) and os.path.isdir(source_path):\n",
        "  HfApi().upload_folder(\n",
        "      folder_path=source_path,\n",
        "      path_in_repo=destination_folder,\n",
        "      repo_id=repo_name,\n",
        "      ignore_patterns=fnmatch_list,\n",
        "  )\n",
        "\n",
        "else:\n",
        "  print(\"{source_path} is not found\")"
      ],
      "metadata": {
        "id": "ccbDfX1zqC7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lOBTBhrXjchu",
        "cZtl8zeNj70a"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}